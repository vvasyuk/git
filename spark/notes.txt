SELECTING DATA
postsDf.select("id", "body")
postsDf.select(postsDf.col("id"), postsDf.col("body"))
postsDf.select(Symbol("id"), Symbol("body"))
postsDf.select('id, 'body)
postsDf.select($"id", $"body")
postsIdBody.drop("body")

FILTERING DATA
postsIdBody.filter('body contains "Italiano").count
postsDf.filter(('postTypeId === 1) and ('acceptedAnswerId isNull))
postsDf.filter('postTypeId === 1).limit(10)

ADDING AND RENAMING COLUMNS
firstTenQs.withColumnRenamed("ownerUserId", "owner")
postsDf.filter('postTypeId === 1).withColumn("ratio", 'viewCount / 'score).where('ratio < 35).show()

USING BUILT-IN SCALAR AND AGGREGATE FUNCTIONS
import org.apache.spark.sql.functions._
postsDf.select(avg('score), max('score), count('score)).show

WINDOW FUNCTIONS
import org.apache.spark.sql.expressions.Window
postsDf.filter('postTypeId === 1).
    select('ownerUserId, 'acceptedAnswerId, 'score, max('score).
        over(Window.partitionBy('ownerUserId)) as "maxPerUser").
        withColumn("toMax", 'maxPerUser - 'score).show(10)
postsDf.filter('postTypeId === 1).
    select('ownerUserId, 'id, 'creationDate,
    lag('id, 1).over(
    Window.partitionBy('ownerUserId).orderBy('creationDate)) as "prev",
    lead('id, 1).over(
    Window.partitionBy('ownerUserId).orderBy('creationDate)) as "next").
    orderBy('ownerUserId, 'id).show(10)

USER-DEFINED FUNCTIONS
val countTags = udf((tags: String) => "&lt;".r.findAllMatchIn(tags).length)
val countTags = spark.udf.register("countTags", (tags: String) => "&lt;".r.findAllMatchIn(tags).length)
postsDf.filter('postTypeId === 1).select('tags, countTags('tags) as "tagCnt").show(10, false)

USER-DEFINED FUNCTIONS WITH CURRYING
import org.apache.spark.sql.functions._
def uDF(strList: List[String]) = udf[String, Int, String, String]((value1: Int, value2: String, value3: String) => value1.toString + "_" + value2 + "_" + value3 + "_" + strList.mkString("_"))
val df = spark.sparkContext.parallelize(Seq((1,"r1c1","r1c2"),(2,"r2c1","r2c2"))).toDF("id","str1","str2")
scala> df.show
+---+----+----+
| id|str1|str2|
+---+----+----+
|  1|r1c1|r1c2|
|  2|r2c1|r2c2|
+---+----+----+
val dummyList = List("dummy1","dummy2")
val result = df.withColumn("new_col", uDF(dummyList)(df("id"),df("str1"),df("str2")))
   scala> result.show(2, false)
+---+----+----+-------------------------+
|id |str1|str2|new_col                  |
+---+----+----+-------------------------+
|1  |r1c1|r1c2|1_r1c1_r1c2_dummy1_dummy2|
|2  |r2c1|r2c2|2_r2c1_r2c2_dummy1_dummy2|
+---+----+----+-------------------------+